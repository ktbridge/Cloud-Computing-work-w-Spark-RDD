# Cloud-Computing-work-w-Spark-RDD
The directory with reference to Professor Yingmao’s spark-examples repository:
/spark-examples/test-python/lab2.

1.	Place the folders task1, task2 and task3 in the mentioned directory
2.	Copy the data for each of the tasks in their corresponding folders only.
Example : shot_logs.csv in task1
     Parking_Violoations_2022.csv in task2 and task3

Run the start-all.sh and all the spark.sbin/start.sh


In each of the individual “task#” folders:
Use “bash test.sh” to get the outputs as mentioned in the report 
